# ğŸ§  ComparaÃ§Ã£o de Arquiteturas CNN no Dataset Fashion-MNIST

## ğŸ¯ Objetivo
O objetivo deste projeto Ã© **comparar duas arquiteturas diferentes de Redes Neurais Convolucionais (CNNs)** na tarefa de **classificaÃ§Ã£o de imagens de roupas** utilizando o dataset **Fashion-MNIST**.  
A proposta busca analisar o impacto da profundidade da rede no desempenho do modelo, considerando acurÃ¡cia, tempo de treinamento e capacidade de generalizaÃ§Ã£o.

---

## ğŸ§© Arquiteturas Implementadas

### ğŸ§± CNN Shallow (Rasa)
- **DescriÃ§Ã£o:** Modelo com **apenas uma camada convolucional**, porÃ©m mais larga.
- **PropÃ³sito:** Captar **padrÃµes simples e locais** nas imagens, como bordas e linhas.
- **Camadas Principais:**
  - Conv2D (filtros amplos)
  - MaxPooling2D
  - Flatten
  - Dense (camada totalmente conectada)
  - Dropout (para evitar overfitting)

### ğŸ—ï¸ CNN Deep (Profunda)
- **DescriÃ§Ã£o:** Modelo com **quatro camadas convolucionais**, tornando-se mais especializado.
- **PropÃ³sito:** Aprender **padrÃµes hierÃ¡rquicos e complexos**, como texturas, partes e objetos completos.
- **Camadas Principais:**
  - MÃºltiplas Conv2D + MaxPooling2D
  - Flatten
  - Dense
  - Dropout

---

## ğŸ“¦ Dataset
**Fashion-MNIST**  
- ContÃ©m **70.000 imagens em tons de cinza (28x28 pixels)** de roupas e acessÃ³rios.
- **10 classes**: camiseta, calÃ§a, pulÃ´ver, vestido, casaco, sandÃ¡lia, camisa, tÃªnis, bolsa e bota.
- O dataset Ã© dividido em:
  - 60.000 imagens para treinamento  
  - 10.000 imagens para teste

---

## âš™ï¸ Tecnologias Utilizadas
- **Python 3.10+**
- **TensorFlow / Keras**
- **NumPy**
- **Matplotlib**
- **Seaborn**
- **time** (para mediÃ§Ã£o de desempenho)

---

## ğŸš€ ExecuÃ§Ã£o do Projeto

### PrÃ©-requisitos
Certifique-se de ter as bibliotecas instaladas:
```bash
pip install tensorflow numpy matplotlib seaborn
```

### Passos para execuÃ§Ã£o
1. Abra o notebook `projeto2_Juliano_Joao_Felizardo.ipynb`.
2. Execute as cÃ©lulas na ordem:
   - ImportaÃ§Ã£o das bibliotecas
   - Carregamento e normalizaÃ§Ã£o dos dados
   - DefiniÃ§Ã£o e compilaÃ§Ã£o dos modelos (Shallow e Deep)
   - Treinamento e validaÃ§Ã£o
   - AvaliaÃ§Ã£o e comparaÃ§Ã£o dos resultados
3. Observe os resultados impressos e os grÃ¡ficos de acurÃ¡cia, perda e tempo de execuÃ§Ã£o.

---

## ğŸ“Š Resultados Obtidos

| Modelo       | AcurÃ¡cia de Teste | Tempo de Treinamento (s) | ObservaÃ§Ãµes |
|---------------|-------------------|---------------------------|--------------|
| CNN Shallow   | 0.9151              | 34.91                        | Mais rÃ¡pida, mas menos precisa |
| CNN Deep      | 0.9238             | 73.40                       | Melhor desempenho geral |

---

## ğŸ§  ConclusÃ£o
- A **CNN Shallow** apresentou bom desempenho para tarefas simples, com treinamento rÃ¡pido.  
- A **CNN Deep** obteve **maior acurÃ¡cia e melhor generalizaÃ§Ã£o**, embora com maior custo computacional.  
- O estudo demonstra como **a profundidade da rede influencia na capacidade de aprendizado** de padrÃµes mais complexos.

---

## ğŸ‘¨â€ğŸ’» Autores
**JoÃ£o Victor de MendonÃ§a Felizardo Silva**

**Juliano**

